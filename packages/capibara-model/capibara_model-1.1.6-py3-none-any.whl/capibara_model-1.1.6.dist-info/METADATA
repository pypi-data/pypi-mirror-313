Metadata-Version: 2.1
Name: capibara_model
Version: 1.1.6
Summary: Language model with contextual processing
Home-page: https://github.com/anachroni-io/capibara-model
Author: Marco DurÃ¡n
Author-email: marco@anachroni.co
Project-URL: Documentation, https://capibara-model.readthedocs.io
Project-URL: Source, https://github.com/anachroni-io/capibara-model
Project-URL: Issues, https://github.com/anachroni-io/capibara-model/issues
Keywords: machine-learning nlp language-model tpu jax
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.8
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: jax>=0.4.1
Requires-Dist: flax>=0.6.0
Requires-Dist: optax>=0.1.3
Requires-Dist: numpy>=1.21.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: mypy>=0.950; extra == "dev"
Provides-Extra: tpu
Requires-Dist: jax[tpu]>=0.4.1; extra == "tpu"

# ğŸ¦« CapibaraModel

Language model with contextual processing based on JAX/Flax.

## âœ¨ Features

- **ğŸ§  Architecture**:
  - ğŸ”„ Multi-head attention
  - ğŸ¯ Contextual activation
  - ğŸ” Coherence detection
  - ğŸ­ Personality management

- **âš¡ Optimizations**:
  - ğŸš€ Native TPU support
  - âš™ï¸ Efficient processing
  - ğŸ“¦ Optimized batching
  - ğŸ•¸ï¸ Integrated sparsity

## ğŸ“‹ Requirements

- Python >= 3.8
- JAX >= 0.4.1
- Flax >= 0.6.0
- Optax >= 0.1.3

## ğŸš€ Installation

```bash
pip install capibara_model
```

## ğŸ’» Usage

### Basic Example

```python
from capibara_model.core.model import CapibaraModel
from capibara_model.core.inference import CapibaraInference

# Create model
model = CapibaraModel(hidden_size=768, num_heads=8)

# Create inference
inference = CapibaraInference(hidden_size=768)

# Generate response
response = inference("How are you?")
print(response)
```

### Advanced Example

```python
# Custom configuration
config = {
    'model': {
        'hidden_size': 1024,
        'num_heads': 16,
        'num_layers': 24,
        'dropout_rate': 0.1
    },
    'training': {
        'batch_size': 32,
        'learning_rate': 1e-4,
        'warmup_steps': 1000
    }
}

# Create model with custom config
model = CapibaraModel(**config['model'])

# Process conversation
context = "Previous conversation context..."
response = inference(
    "What's the meaning of life?",
    context=context
)
```

## âš™ï¸ Configuration

```python
config = {
    'hidden_size': 768,
    'num_heads': 8,
    'num_layers': 12,
    'dropout_rate': 0.1,
    'use_tpu': False
}
```

## ğŸ› ï¸ Development

```bash
# Install development dependencies
pip install capibara_model[dev]

# Run tests
pytest tests/

# Run specific test
pytest tests/test_model.py -k "test_attention"

# Check code style
black capibara_model/
```

## ğŸ“ License

MIT License. See `LICENSE` for more information.

## ğŸ“« Contact

Marco DurÃ¡n - [marco@anachroni.co](mailto:marco@anachroni.co)

[ğŸŒ Website](https://www.anachroni.co) | [ğŸ’» GitHub](https://github.com/anachroni-io/CapibaraModel)

## ğŸ™ Acknowledgments

Special thanks to:

- JAX/Flax team
- TPU Research Cloud
- Open source community
