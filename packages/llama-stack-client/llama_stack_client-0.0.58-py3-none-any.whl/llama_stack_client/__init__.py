# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from . import types
from ._base_client import DefaultAsyncHttpxClient, DefaultHttpxClient
from ._types import NoneType, NOT_GIVEN, NotGiven, Omit, ProxiesTypes, Transport
from ._client import (
    AsyncClient,
    AsyncLlamaStackClient,
    AsyncStream,
    Client,
    LlamaStackClient,
    RequestOptions,
    Stream,
    Timeout,
    Transport,
)
from ._constants import DEFAULT_CONNECTION_LIMITS, DEFAULT_MAX_RETRIES, DEFAULT_TIMEOUT
from ._exceptions import (
    APIConnectionError,
    APIError,
    APIResponseValidationError,
    APIStatusError,
    APITimeoutError,
    AuthenticationError,
    BadRequestError,
    ConflictError,
    InternalServerError,
    LlamaStackClientError,
    NotFoundError,
    PermissionDeniedError,
    RateLimitError,
    UnprocessableEntityError,
)
from ._models import BaseModel
from ._response import APIResponse as APIResponse, AsyncAPIResponse as AsyncAPIResponse
from ._utils import file_from_path
from ._utils._logs import setup_logging as _setup_logging
from ._version import __title__, __version__

__all__ = [
    "types",
    "__version__",
    "__title__",
    "NoneType",
    "Transport",
    "ProxiesTypes",
    "NotGiven",
    "NOT_GIVEN",
    "Omit",
    "LlamaStackClientError",
    "APIError",
    "APIStatusError",
    "APITimeoutError",
    "APIConnectionError",
    "APIResponseValidationError",
    "BadRequestError",
    "AuthenticationError",
    "PermissionDeniedError",
    "NotFoundError",
    "ConflictError",
    "UnprocessableEntityError",
    "RateLimitError",
    "InternalServerError",
    "Timeout",
    "RequestOptions",
    "Client",
    "AsyncClient",
    "Stream",
    "AsyncStream",
    "LlamaStackClient",
    "AsyncLlamaStackClient",
    "file_from_path",
    "BaseModel",
    "DEFAULT_TIMEOUT",
    "DEFAULT_MAX_RETRIES",
    "DEFAULT_CONNECTION_LIMITS",
    "DefaultHttpxClient",
    "DefaultAsyncHttpxClient",
]


# Only expose the direct client if its dependencies are installed
class _MissingDependencyProxy:
    def __init__(self, import_error):
        self._error = f"LlamaStackDirectClient is not available because its dependencies are not installed. Original error: {import_error}"

    def __getattr__(self, _):
        raise ImportError(self._error)

    def __call__(self, *args, **kwargs):
        raise ImportError(self._error)


try:
    from .lib.direct.direct import LlamaStackDirectClient

    __all__.append("LlamaStackDirectClient")
except ImportError as e:
    LlamaStackDirectClient = _MissingDependencyProxy(e)

_setup_logging()

# Update the __module__ attribute for exported symbols so that
# error messages point to this module instead of the module
# it was originally defined in, e.g.
# llama_stack_client._exceptions.NotFoundError -> llama_stack_client.NotFoundError
__locals = locals()
for __name in __all__:
    if not __name.startswith("__"):
        try:
            __locals[__name].__module__ = "llama_stack_client"
        except (TypeError, AttributeError):
            # Some of our exported symbols are builtins which we can't set attributes for.
            pass
