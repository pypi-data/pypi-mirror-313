Metadata-Version: 2.3
Name: prompt_llm
Version: 0.1.0
Summary: A CLI tool to prompt LLMs
Project-URL: Homepage, https://github.com/reego-software/prompt_llm
Project-URL: Issues, https://github.com/reego-software/prompt_llm/issues
Author-email: Hasan YILMAZ <yilmazhasan111@gmail.com>
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.8
Requires-Dist: langchain-core
Requires-Dist: langchain-mistralai
Requires-Dist: langchain-openai
Requires-Dist: typer
Description-Content-Type: text/markdown

# prompt_llm

## Version
0.1.0

- Prompt LLMs via cli

## Installation

1. Clone the repo

2. Install
- Local:
    - `pip install --editable .`
- PyPi:
    - `pip install prompt_llm`

3. Install auto-completion:
- `prompt_llm --install-completion`
- `source ~/.bashrc`

## Config:
- Supported configs: `--system`, `--temperature`, `--api-key`

### Set Config
- `add_config  --api-key "<api_key>" --system "<system_messgae>" --temperature <temperature>`

### Remove Config:

- `prompt_llm rm-config temperature`

## Run cli
- `prompt_llm openai "Tell me something"`

