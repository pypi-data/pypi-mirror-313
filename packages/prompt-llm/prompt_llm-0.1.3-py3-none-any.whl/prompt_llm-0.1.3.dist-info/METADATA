Metadata-Version: 2.3
Name: prompt_llm
Version: 0.1.3
Summary: A CLI tool to prompt LLMs
Project-URL: Homepage, https://github.com/reego-software/prompt_llm
Project-URL: Issues, https://github.com/reego-software/prompt_llm/issues
Author-email: Hasan YILMAZ <yilmazhasan111@gmail.com>
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.8
Requires-Dist: langchain-cohere
Requires-Dist: langchain-core
Requires-Dist: langchain-fireworks
Requires-Dist: langchain-google-vertexai
Requires-Dist: langchain-groq
Requires-Dist: langchain-mistralai
Requires-Dist: langchain-nvidia-ai-endpoints
Requires-Dist: langchain-openai
Requires-Dist: typer
Description-Content-Type: text/markdown

# prompt_llm

## Version
0.1.3

- Prompt LLMs via cli

## Installation

1. Clone the repo

2. Install
- Local:
    - `pip install --editable .`
- PyPi:
    - `pip install prompt_llm`

3. Install auto-completion:
- `prompt_llm --install-completion`
- `source ~/.bashrc`

## Config:
- Supported configs: `--api-key`, `model`, `--system`, `--temperature`

### Set Config
- `add_config  --api-key "<api_key>" --system "<system_messgae>" --temperature <temperature>`

### Remove Config:
- `prompt_llm rm-config temperature`

### View Config:
- `prompt_llm view-config`

## Run cli
- `prompt_llm openai "Tell me something"`


## To contribute

### 1. Build project
`python -m build`

###Â 2. Upload
`python3 -m twine upload --repository pypi dist/* --verbose`