Metadata-Version: 2.1
Name: homa
Version: 3.3
Maintainer: Taha Shieenavaz
Maintainer-email: tahashieenavaz@gmail.com
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torchvision
Requires-Dist: torch

# Homa

- [Homa](#homa)
  - [Helpers](#helpers)
    - [get\_device](#get_device)
    - [pickle](#pickle)
  - [Transformers](#transformers)
    - [positional\_encoding](#positional_encoding)

<div align="center">
    <img src="https://github.com/tahashieenavaz/homa/raw/main/art/homa.svg" width="500" />
</div>

## Helpers

### get_device

```py
from homa import get_device

torch.tensor(torch.randint(-20, 10, (32, 10))).to(get_device())
```

### pickle

```py
from homa import pickle

person = {"name": "John Doe", age: 88}
pickle(person, "person.pkl")

loaded_person = pickle("person.pkl")
```

## Transformers

### positional_encoding

```py
from homa import positional_encoding

class TransformerModel(torch.nn.Module):
    def __init__(self, seq_length, dimension):
        # ...
        self.positional_encoding = positional_encoding(seq_length, dimension)

    def forward(self, x):
        # ...
        x = x + self.positional_encoding
```
