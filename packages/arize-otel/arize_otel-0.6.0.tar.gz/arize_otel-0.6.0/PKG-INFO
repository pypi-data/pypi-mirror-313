Metadata-Version: 2.3
Name: arize-otel
Version: 0.6.0
Summary: Helper package for OTEL setup to send traces to Arize & Phoenix
Project-URL: Documentation, https://docs.arize.com/arize/large-language-models/tracing
Project-URL: Issues, https://github.com/Arize-ai/arize-otel-python/issues
Project-URL: Source, https://github.com/Arize-ai/arize-otel-python
Project-URL: Changelog, https://github.com/Arize-ai/arize-otel-python/blob/main/CHANGELOG.md
Author-email: Arize AI <support@arize.com>
Maintainer-email: Arize AI <support@arize.com>
License: BSD
Keywords: Explainability,Monitoring,Observability,Tracing
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: System :: Logging
Classifier: Topic :: System :: Monitoring
Requires-Python: <3.13,>=3.8
Requires-Dist: openinference-semantic-conventions>=0.1.5
Requires-Dist: opentelemetry-exporter-otlp>=1.22
Requires-Dist: opentelemetry-proto>=1.12.0
Requires-Dist: opentelemetry-sdk>=1.22
Description-Content-Type: text/markdown

<p align="center">
    <a target="_blank" href="https://phoenix.arize.com" style="background:none">
        <img alt="arize banner" src="https://storage.googleapis.com/arize-assets/arize-logo-white.jpg"  width="auto" height="auto"></img>
    </a>
    <br/>
    <br/>
    <a href="https://docs.arize.com/">
        <img src="https://img.shields.io/static/v1?message=Docs&logo=data:image/png;base64,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&labelColor=grey&color=blue&logoColor=white&label=%20"/>
    </a>
    <a target="_blank" href="https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q">
        <img src="https://img.shields.io/static/v1?message=Community&logo=slack&labelColor=grey&color=blue&logoColor=white&label=%20"/>
    </a>
    <br/>
    <a target="_blank" href="https://pypi.org/project/arize-otel/">
        <img src="https://img.shields.io/pypi/v/arize-otel">
    </a>
    <a target="_blank" href="https://pypi.org/project/arize-otel/">
        <img src="https://img.shields.io/pypi/status/arize-otel?style=flat&logo=ticktick&logoColor=white"/>
    </a>
    <a target="_blank" href="https://pypi.org/project/arize-otel/">
        <img src="https://img.shields.io/pypi/pyversions/arize-otel?logo=python&logoColor=white">
    </a>
    <a target="_blank" href="https://github.com/Arize-ai/arize-otel-python/blob/main/LICENSE">
        <img src="https://img.shields.io/pypi/l/arize-otel">
    </a>

</p>

---

## Overview

The `arize-otel` package is meant to be a very lightweight convenience package to help set up OpenTelemetry for tracing LLM applications
and send the traces to [Arize](https://arize.com/), [Phoenix](https://phoenix.arize.com/), or custom collectors.

## Installation

Install `arize-otel` using `pip`

```bash
pip install arize-otel
```

## Quickstart

You only need one import to use this package:

```python
from arize_otel import register_otel, Endpoints
```

The following examples showcase how to use `register_otel` to setup Opentelemetry in order to send traces to a collector. However,
this is **NOT** the same as [instrumenting](https://docs.arize.com/phoenix/tracing/concepts-tracing/how-does-tracing-work)
your application. For instance, you can use any of our [OpenInference AutoInstrumentators](https://github.com/Arize-ai/openinference).
Assuming we use the OpenAI AutoInstrumentation, we need to run `instrument()` _after_ using `register_otel`:

```python
# Setup OTEL via our convenience function
register_otel(
    # See details in examples below...
)

# Instrument your application using OpenInference AutoInstrumentators
from openinference.instrumentation.openai import OpenAIInstrumentor
OpenAIInstrumentor().instrument()

```

The above code snippet will yield a fully setup and instrumented application. It is worth noting that this is completely **optional**. The usage of this
package is for convenience only, you can set up OpenTelemetry and send traces to Arize and Phoenix without installing this or any other package from Arize.

In the following sections we have examples on how to use the `register_otel` function:

### Send traces to Arize

To send traces to Arize you need to authenticate via the Space ID and API Key. You can find them in the Space Settings page in the Arize platform. In addition,
you'll need to specify the model ID, an unique name to identify your model in the Arize platform. Optionally, you can set the model version, which serves to
to group a subset of data, given the same model ID, to compare and track changes.

```python
register_otel(
    endpoints = Endpoints.ARIZE,
    space_id = "your-arize-space-id",
    api_key = "your-arize-api-key",
    model_id = "your-model-id",
    model_version = "your-model-version", # OPTIONAL
)
```

### Send traces to Local Phoenix

To send traces to your local Phoenix server you just need to provide the correct endpoint. In the example below we have specified the local Phoenix endpoint,
but you can specify your own (explained in an example below). Optionally, you can specify a project to send the traces to. A project is a collection of traces that
are related to a single application or service. You can have multiple projects, each with multiple traces.

Send traces via HTTP:

```python
register_otel(
    endpoints = Endpoints.LOCAL_PHOENIX_HTTP,
    project_name = "your-project-name", # OPTIONAL
)
```

Send traces via gRPC:

```python
register_otel(
    endpoints = Endpoints.LOCAL_PHOENIX_GRPC,
    project_name = "your-project-name", # OPTIONAL
)
```

### Send traces to Hosted Phoenix

To send traces to your [Hosted Phoenix](https://docs.arize.com/phoenix/hosted-phoenix), also known as [Llamatrace](https://llamatrace.com/login), you just need to provide the correct endpoint. In the example below we have specified said endpoint, as well as the Phoenix API key required. Optionally, you can specify a project to which to send the traces, exactly as above with a local Phoenix instance.

```python
register_otel(
    endpoints = Endpoints.HOSTED_PHOENIX,
    api_key = "your-hosted-phoenix-api-key",
    project_name = "your-project-name", # OPTIONAL
)
```

### Send traces to Custom Endpoint

Sending traces to a collector on a custom endpoint is simple, you just need to provide the endpoint. If this endpoint corresponds to an Arize or Phoenix deployment,
you can add any of the options described in the examples above.

```python
register_otel(
    endpoints = "https://my-custom-endpoint"
    # any other options...
)
```

### Send traces to Multiple Endpoints

In this example we send traces to the default Arize and Phoenix endpoints, as well as to a third custom one. We also set all the options mentioned until now.

```python
register_otel(
    endpoints = [
        Endpoints.ARIZE,
        Endpoints.PHOENIX_LOCAL,
        "https://my-custom-endpoint",
    ],
    space_id = "your-space-id",
    api_key = "your-api-key",
    model_id = "your-model-id",
    model_version = "your-model-version", # OPTIONAL
    project_name = "your-project-name", # OPTIONAL
)
```

### Debug

As you're setting up your tracing, it is helpful to print to console the spans created. You can achieve this by setting `log_to_console=True`.

```python
register_otel(
    # other options...
    log_to_console=True
)
```

### Turn off batch processing of spans

We default to using [BatchSpanProcessor](https://opentelemetry.io/docs/languages/js/instrumentation/#picking-the-right-span-processor) from OpenTelemetry because it is non-blocking in case telemetry goes down. In contrast, "SimpleSpanProcessor processes spans as they are created." This can be helpful in development. You can use `SimpleSpanProcessor` with the option `use_batch_processor=False`.

```python
register_otel(
    # other options...
    use_batch_processor=False
)
```

## Questions?

Find us in our [Slack Community](https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q) or email support@arize.com

## Copyright, Patent, and License

Copyright 2024 Arize AI, Inc. All Rights Reserved.

This software is licensed under the terms of the 3-Clause BSD License. See [LICENSE](https://github.com/Arize-ai/arize-otel-python/blob/main/LICENSE).
